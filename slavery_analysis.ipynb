{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the Drivers of Modern Slavery\n",
    "\n",
    "Even though slavery is illegal, forty million people are estimated to live under some form of modern slavery across the globe. These forms of modern slavery include a wide variety of practices such as forced labour, debt bondage, forced marriage, sexual exploitation, bonded labour, and human trafficking.\n",
    " \n",
    "Researchers have been trying to estimate the prevalence of modern slavery, as well as factors that can help with this prediction. Machine Learning techniques can help in this endeavour, as has been shown in the following publication:\n",
    "\n",
    "* Lavelle-Hill, R., Smith, G., Mazumder, A. et al. Machine learning methods for \"wicked\" problems: exploring the complex drivers of modern slavery. Humanities and Social Sciences Communications 8, 274 (2021). https://doi.org/10.1057/s41599-021-00938-z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Data_year</th>\n",
       "      <th>Region</th>\n",
       "      <th>KOF_Globalis</th>\n",
       "      <th>Work_rightCIRI</th>\n",
       "      <th>Trade_open</th>\n",
       "      <th>FDI</th>\n",
       "      <th>VDEM_Libdem</th>\n",
       "      <th>GDPpc_2016</th>\n",
       "      <th>Armedcon</th>\n",
       "      <th>...</th>\n",
       "      <th>Pol_right_F_2011</th>\n",
       "      <th>Indep_judic_2011</th>\n",
       "      <th>Rape_prev_2018</th>\n",
       "      <th>Rape_report_2015</th>\n",
       "      <th>Rape_enclave_2015</th>\n",
       "      <th>Rape_compl_2018</th>\n",
       "      <th>Phys_secF_2014</th>\n",
       "      <th>Phys_secF_2019</th>\n",
       "      <th>Gender_equal_2015</th>\n",
       "      <th>Hum_traff_2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>ASIA</td>\n",
       "      <td>38.57</td>\n",
       "      <td>1</td>\n",
       "      <td>55.92</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.24</td>\n",
       "      <td>570</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>AMERICAS</td>\n",
       "      <td>63.02</td>\n",
       "      <td>1</td>\n",
       "      <td>26.12</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.61</td>\n",
       "      <td>11970</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>RUSSIA AND EURASIA</td>\n",
       "      <td>67.09</td>\n",
       "      <td>1</td>\n",
       "      <td>75.92</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.23</td>\n",
       "      <td>3770</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>ASIA</td>\n",
       "      <td>45.54</td>\n",
       "      <td>0</td>\n",
       "      <td>37.95</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1330</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bolivia</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>AMERICAS</td>\n",
       "      <td>57.74</td>\n",
       "      <td>1</td>\n",
       "      <td>56.40</td>\n",
       "      <td>1.54</td>\n",
       "      <td>0.40</td>\n",
       "      <td>3070</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Country  Data_year              Region  KOF_Globalis  Work_rightCIRI  \\\n",
       "0  Afghanistan 2018-01-01                ASIA         38.57               1   \n",
       "1    Argentina 2018-01-01            AMERICAS         63.02               1   \n",
       "2      Armenia 2018-01-01  RUSSIA AND EURASIA         67.09               1   \n",
       "3   Bangladesh 2016-01-01                ASIA         45.54               0   \n",
       "4      Bolivia 2016-01-01            AMERICAS         57.74               1   \n",
       "\n",
       "   Trade_open   FDI  VDEM_Libdem  GDPpc_2016  Armedcon  ...  Pol_right_F_2011  \\\n",
       "0       55.92  0.48         0.24         570         1  ...                 2   \n",
       "1       26.12  0.59         0.61       11970         0  ...                 3   \n",
       "2       75.92  3.21         0.23        3770         0  ...                 2   \n",
       "3       37.95  1.05         0.16        1330         1  ...                 2   \n",
       "4       56.40  1.54         0.40        3070         0  ...                 3   \n",
       "\n",
       "   Indep_judic_2011  Rape_prev_2018  Rape_report_2015  Rape_enclave_2015  \\\n",
       "0                 0             4.0               4.0                2.0   \n",
       "1                 1             1.0               4.0                0.0   \n",
       "2                 0             0.0               3.0                0.0   \n",
       "3                 0             1.0               4.0                1.0   \n",
       "4                 0             3.0               3.0                0.0   \n",
       "\n",
       "   Rape_compl_2018  Phys_secF_2014  Phys_secF_2019  Gender_equal_2015  \\\n",
       "0             17.0             4.0             4.0                2.0   \n",
       "1              9.0             3.0             2.0                4.0   \n",
       "2              9.0             4.0             3.0                0.0   \n",
       "3             12.0             4.0             4.0                4.0   \n",
       "4             10.0             3.0             3.0                0.0   \n",
       "\n",
       "   Hum_traff_2019  \n",
       "0             3.0  \n",
       "1             1.0  \n",
       "2             3.0  \n",
       "3             3.0  \n",
       "4             3.0  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"training.csv\")\n",
    "data['Data_year'] = pd.to_datetime(data['Data_year'], format='%Y')\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dependent variable of our dataset is `\"SLAVERY\"`, which showcases the slavery percentage of the population of each country.\n",
    "\n",
    "- 48 unique countries\n",
    "\n",
    "- Years between 2016 & 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KOF_Globalis</th>\n",
       "      <th>Work_rightCIRI</th>\n",
       "      <th>Trade_open</th>\n",
       "      <th>FDI</th>\n",
       "      <th>VDEM_Libdem</th>\n",
       "      <th>GDPpc_2016</th>\n",
       "      <th>Armedcon</th>\n",
       "      <th>Asia</th>\n",
       "      <th>Subsah_Africa</th>\n",
       "      <th>Americas</th>\n",
       "      <th>...</th>\n",
       "      <th>Pol_right_F_2011</th>\n",
       "      <th>Indep_judic_2011</th>\n",
       "      <th>Rape_prev_2018</th>\n",
       "      <th>Rape_report_2015</th>\n",
       "      <th>Rape_enclave_2015</th>\n",
       "      <th>Rape_compl_2018</th>\n",
       "      <th>Phys_secF_2014</th>\n",
       "      <th>Phys_secF_2019</th>\n",
       "      <th>Gender_equal_2015</th>\n",
       "      <th>Hum_traff_2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>67.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>61.689857</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>77.148143</td>\n",
       "      <td>4.552000</td>\n",
       "      <td>0.401143</td>\n",
       "      <td>5398.000000</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.328571</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>...</td>\n",
       "      <td>2.071429</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>1.415385</td>\n",
       "      <td>3.462687</td>\n",
       "      <td>0.925373</td>\n",
       "      <td>11.061538</td>\n",
       "      <td>3.492537</td>\n",
       "      <td>3.283582</td>\n",
       "      <td>2.462687</td>\n",
       "      <td>2.283582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.496019</td>\n",
       "      <td>0.546208</td>\n",
       "      <td>48.522488</td>\n",
       "      <td>10.682218</td>\n",
       "      <td>0.189771</td>\n",
       "      <td>7055.343047</td>\n",
       "      <td>0.478091</td>\n",
       "      <td>0.473085</td>\n",
       "      <td>0.422944</td>\n",
       "      <td>0.379604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428054</td>\n",
       "      <td>0.762066</td>\n",
       "      <td>1.197554</td>\n",
       "      <td>0.658933</td>\n",
       "      <td>0.840516</td>\n",
       "      <td>2.098191</td>\n",
       "      <td>0.560658</td>\n",
       "      <td>0.754903</td>\n",
       "      <td>1.786552</td>\n",
       "      <td>0.754903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>38.570000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.720000</td>\n",
       "      <td>-37.170000</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54.405000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.057500</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.232500</td>\n",
       "      <td>1385.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>61.875000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>64.900000</td>\n",
       "      <td>2.660000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>3580.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>69.682500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.635000</td>\n",
       "      <td>5.270000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>6750.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>84.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>310.260000</td>\n",
       "      <td>55.490000</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>51880.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       KOF_Globalis  Work_rightCIRI  Trade_open        FDI  VDEM_Libdem  \\\n",
       "count     70.000000       70.000000   70.000000  70.000000    70.000000   \n",
       "mean      61.689857        0.614286   77.148143   4.552000     0.401143   \n",
       "std       11.496019        0.546208   48.522488  10.682218     0.189771   \n",
       "min       38.570000        0.000000   20.720000 -37.170000     0.110000   \n",
       "25%       54.405000        0.000000   43.057500   1.100000     0.232500   \n",
       "50%       61.875000        1.000000   64.900000   2.660000     0.450000   \n",
       "75%       69.682500        1.000000   99.635000   5.270000     0.550000   \n",
       "max       84.200000        2.000000  310.260000  55.490000     0.780000   \n",
       "\n",
       "         GDPpc_2016   Armedcon       Asia  Subsah_Africa   Americas  ...  \\\n",
       "count     70.000000  70.000000  70.000000      70.000000  70.000000  ...   \n",
       "mean    5398.000000   0.342857   0.328571       0.228571   0.171429  ...   \n",
       "std     7055.343047   0.478091   0.473085       0.422944   0.379604  ...   \n",
       "min      320.000000   0.000000   0.000000       0.000000   0.000000  ...   \n",
       "25%     1385.000000   0.000000   0.000000       0.000000   0.000000  ...   \n",
       "50%     3580.000000   0.000000   0.000000       0.000000   0.000000  ...   \n",
       "75%     6750.000000   1.000000   1.000000       0.000000   0.000000  ...   \n",
       "max    51880.000000   1.000000   1.000000       1.000000   1.000000  ...   \n",
       "\n",
       "       Pol_right_F_2011  Indep_judic_2011  Rape_prev_2018  Rape_report_2015  \\\n",
       "count         70.000000         70.000000       65.000000         67.000000   \n",
       "mean           2.071429          0.642857        1.415385          3.462687   \n",
       "std            0.428054          0.762066        1.197554          0.658933   \n",
       "min            1.000000          0.000000        0.000000          2.000000   \n",
       "25%            2.000000          0.000000        1.000000          3.000000   \n",
       "50%            2.000000          0.000000        1.000000          4.000000   \n",
       "75%            2.000000          1.000000        2.000000          4.000000   \n",
       "max            3.000000          2.000000        4.000000          4.000000   \n",
       "\n",
       "       Rape_enclave_2015  Rape_compl_2018  Phys_secF_2014  Phys_secF_2019  \\\n",
       "count          67.000000        65.000000       67.000000       67.000000   \n",
       "mean            0.925373        11.061538        3.492537        3.283582   \n",
       "std             0.840516         2.098191        0.560658        0.754903   \n",
       "min             0.000000         7.000000        2.000000        2.000000   \n",
       "25%             0.000000        10.000000        3.000000        3.000000   \n",
       "50%             1.000000        11.000000        4.000000        3.000000   \n",
       "75%             2.000000        12.000000        4.000000        4.000000   \n",
       "max             2.000000        17.000000        4.000000        4.000000   \n",
       "\n",
       "       Gender_equal_2015  Hum_traff_2019  \n",
       "count          67.000000       67.000000  \n",
       "mean            2.462687        2.283582  \n",
       "std             1.786552        0.754903  \n",
       "min             0.000000        1.000000  \n",
       "25%             1.000000        2.000000  \n",
       "50%             3.000000        2.000000  \n",
       "75%             4.000000        3.000000  \n",
       "max             6.000000        4.000000  \n",
       "\n",
       "[8 rows x 117 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `1) Data preprocesing `"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to relative lack of data, the researchers first grouped the metrics to 2 distinct groups, those that were estimated before 2016 and those after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "group1 = data[data['Data_year'] <= '2016-01-01']\n",
    "group2 = data[data['Data_year'] > '2016-01-01']\n",
    "\n",
    "data = pd.concat([group1, group2], axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, the researchers removed the variables that had over 50% missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = data.isna().mean()\n",
    "columns_to_keep = missing_data[missing_data <= 0.5].index\n",
    "data = data[columns_to_keep]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally for the first part of data pre-processing, they filled missing values for countries with data available in either 2016 or 2018:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for country in data['Country'].unique():\n",
    "    country_data = data[data['Country'] == country]\n",
    "    data.loc[data['Country'] == country, :] = country_data.fillna(method='ffill').fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute remaining missing values using multivariate feature imputation with regression trees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lefterisfthenos/Desktop/MSBA - AUEB/Semester 2 /Analytics Practicum I/practicum_venv/lib/python3.9/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "imputer = IterativeImputer(estimator=DecisionTreeRegressor(), random_state=42)\n",
    "data_imputed = imputer.fit_transform(data.drop(columns=['Country', 'Data_year', 'Region']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize variables between 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "data_normalized = scaler.fit_transform(data_imputed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the imputed and normalized data back to a DataFrame and reattach non-numeric columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [col for col in data.columns if col not in ['Country', 'Data_year', 'Region']]\n",
    "data_processed = pd.DataFrame(data_normalized, columns=columns)\n",
    "data_processed['Country'] = data['Country'].values\n",
    "data_processed['Data_year'] = data['Data_year'].values\n",
    "data_processed['Region'] = data['Region'].values\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `2. Slavery Estimation Using All Features`\n",
    "\n",
    "We will use [Out of Sample data](oos_data.csv) to evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "oos_data = pd.read_csv(\"oos_data.csv\")\n",
    "oos_data['Data_year'] = pd.to_datetime(oos_data['Data_year'], format='%Y')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Column Mapping` between the Out of Sample dataset and the Preprocessed dataset estimated in `Q1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mapping = {\n",
    "    'AIDS_Orph': ['AIDS_Orph_2016', 'AIDS_Orph_2018'],\n",
    "    'GDPpc': 'GDPpc_2016',\n",
    "    'Gender_equal': 'Gender_equal_2015',\n",
    "    'Phys_secF': ['Phys_secF_2014', 'Phys_secF_2019'],\n",
    "    'Rape_enclave': 'Rape_enclave_2015',\n",
    "    'Rape_report': 'Rape_report_2015'\n",
    "}\n",
    "\n",
    "oos_data_updated = oos_data.copy()\n",
    "for old_col, new_col in column_mapping.items():\n",
    "    if isinstance(new_col, list):\n",
    "        oos_data_updated[new_col[0]] = oos_data_updated[old_col]\n",
    "        oos_data_updated[new_col[1]] = oos_data_updated[old_col]\n",
    "    else:\n",
    "        oos_data_updated[new_col] = oos_data_updated[old_col]\n",
    "\n",
    "# Drop the old columns\n",
    "oos_data_updated.drop(column_mapping.keys(), axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to split the dataset into train and test parts - 1 train-test group for pre 2016 and one for post 2016 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We Split the data based on the year\n",
    "train_data_2016 = data_processed[data_processed['Data_year'] == '2016-01-01']\n",
    "train_data_2018 = data_processed[data_processed['Data_year'] != '2016-01-01']\n",
    "\n",
    "test_data_2016 = oos_data_updated[oos_data_updated['Data_year'] == '2016']\n",
    "test_data_2018 = oos_data_updated[oos_data_updated['Data_year'] == '2018']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features and target variable\n",
    "target = 'SLAVERY'\n",
    "common_features = set(train_data_2016.columns).intersection(set(oos_data_updated.columns))\n",
    "\n",
    "features = [col for col in common_features if col not in ['Country', 'Data_year', 'Region', target]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation of the train and test datasets\n",
    "X_train_2016 = train_data_2016[features]\n",
    "y_train_2016 = train_data_2016[target]\n",
    "\n",
    "X_train_2018 = train_data_2018[features]\n",
    "y_train_2018 = train_data_2018[target]\n",
    "\n",
    "X_test_2016 = oos_data_updated[oos_data_updated['Data_year'] == '2016'][features]\n",
    "y_test_2016 = oos_data_updated[oos_data_updated['Data_year'] == '2016'][target]\n",
    "\n",
    "X_test_2018 = oos_data_updated[oos_data_updated['Data_year'] == '2018'][features]\n",
    "y_test_2018 = oos_data_updated[oos_data_updated['Data_year'] == '2018'][target]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since there are still Null values on oos_data dataframe, we can impute the missing values in both the train and test datasets before fitting the models. We will use the SimpleImputer class from scikit-learn to impute the missing values with the mean of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "imputer.fit(X_train_2016)\n",
    "X_train_2016 = imputer.transform(X_train_2016)\n",
    "X_test_2016 = imputer.transform(X_test_2016)\n",
    "\n",
    "# Fit the imputer on the 2018 training data\n",
    "imputer.fit(X_train_2018)\n",
    "\n",
    "X_train_2018 = imputer.transform(X_train_2018)\n",
    "X_test_2018 = imputer.transform(X_test_2018)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we train the models and evaluating them using MAE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Linear Regression - MAE 2016: 5065.07, MAE 2018: 7468.20\n",
      "* Ridge Regression - MAE 2016: 4289.51, MAE 2018: 5354.10\n",
      "* Lasso Regression - MAE 2016: 0.39, MAE 2018: 0.41\n",
      "* Decision Tree - MAE 2016: 0.49, MAE 2018: 0.52\n",
      "* Random Forest - MAE 2016: 0.40, MAE 2018: 0.37\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'Decision Tree': DecisionTreeRegressor(),\n",
    "    'Random Forest': RandomForestRegressor()\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Train and evaluate the model for 2016 data\n",
    "    model.fit(X_train_2016, y_train_2016)\n",
    "    y_pred_2016 = model.predict(X_test_2016)\n",
    "    mae_2016 = mean_absolute_error(y_test_2016, y_pred_2016)\n",
    "    \n",
    "    # Train and evaluate the model for 2018 data\n",
    "    model.fit(X_train_2018, y_train_2018)\n",
    "    y_pred_2018 = model.predict(X_test_2018)\n",
    "    mae_2018 = mean_absolute_error(y_test_2018, y_pred_2018)\n",
    "    \n",
    "    print(f\"* {name} - MAE 2016: {mae_2016:.2f}, MAE 2018: {mae_2018:.2f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In order to extract the 10 most important variables considered by the 'Decision Tree' and 'Random Forest' models, we will make use of their `feature_importances_` element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree - Top 10 Feature Importances:\n",
      "* Neonatal_mort: 0.5462\n",
      "* Water_acc: 0.2233\n",
      "* Sexwrk_HIV: 0.0849\n",
      "* Free_discuss: 0.0582\n",
      "* Prison_pop: 0.0266\n",
      "* Treated_waste: 0.0143\n",
      "* Tuberculosis: 0.0138\n",
      "* F_parliam: 0.0124\n",
      "* Primary_school: 0.0062\n",
      "* Battle_deaths: 0.0036\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "importances_dt = models['Decision Tree'].feature_importances_\n",
    "indices_dt = np.argsort(importances_dt)[-10:]  # Top 10 features\n",
    "import_dt_dict  = dict()\n",
    "print(\"Decision Tree - Top 10 Feature Importances:\")\n",
    "for i in indices_dt[::-1]:\n",
    "    print(f\"* {features[i]}: {importances_dt[i]:.4f}\")\n",
    "    import_dt_dict[features[i]] = importances_dt[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Top 10 Feature Importances:\n",
      "* Neonatal_mort: 0.1689\n",
      "* Internet_use: 0.1319\n",
      "* Piped_water: 0.0692\n",
      "* Tuberculosis: 0.0564\n",
      "* F_school: 0.0535\n",
      "* Water_acc: 0.0505\n",
      "* Climate_chg_vuln: 0.0254\n",
      "* Literacy_15_24yrs: 0.0240\n",
      "* CPI: 0.0225\n",
      "* Yrs_of_school: 0.0225\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "importances_rf = models['Random Forest'].feature_importances_\n",
    "indices_rf = np.argsort(importances_rf)[-10:]\n",
    "print(\"Random Forest - Top 10 Feature Importances:\")\n",
    "import_rf_set = dict()\n",
    "for i in indices_rf[::-1]:\n",
    "    print(f\"* {features[i]}: {importances_rf[i]:.4f}\")\n",
    "    import_rf_set[features[i]] = importances_rf[i]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The common variables considered amongst the top most important ones between the two models can be found by the intersection of the two sets of keys, produced by the dictionaries above: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common Important Variables:\n",
      "*  Tuberculosis\n",
      "*  Neonatal_mort\n",
      "*  Water_acc\n"
     ]
    }
   ],
   "source": [
    "common_importance_vars = set(import_dt_dict.keys()).intersection(set(import_rf_set.keys()))\n",
    "print(\"Common Important Variables:\")\n",
    "for var in common_importance_vars:\n",
    "    print(\"* \", var)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can observe, Neonatal Mortality (per 1000 live births), Net primary school enrolment rate (%), Access to improved water (%) and Incidence of tuberculosis (per 100,000) are the `4 features` providing the highest source of information for predicting the \"Modern Slavery\" from our dataset, in both models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `3. Slavery Estimation with Theory-based Features`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Theory-based selected features of the researchers, were derived from the dataset that can be found [here](https://github.com/ml-slavery/ml-slavery/blob/main/Data/Meta_Data/Variable_descriptions.csv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable Name</th>\n",
       "      <th>Short Variable Description</th>\n",
       "      <th>Source Extracted from</th>\n",
       "      <th>Cited Original Source</th>\n",
       "      <th>Theory Selected?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AIDS_death</td>\n",
       "      <td>Number of AIDS-related deaths</td>\n",
       "      <td>UNAIDS</td>\n",
       "      <td>UNAIDS</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIDS_Orph</td>\n",
       "      <td>AIDS orphans (0-17)</td>\n",
       "      <td>UNAIDS</td>\n",
       "      <td>UNAIDS</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Armedcon</td>\n",
       "      <td>Is there the presence of any type of armed con...</td>\n",
       "      <td>Silverman and Landman (2019)</td>\n",
       "      <td>Uppsala Conflict Data Project (UCDP)</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATMs</td>\n",
       "      <td>Automated teller machines (per 100,000)</td>\n",
       "      <td>UN's SDGs dataset (2018)</td>\n",
       "      <td>IMF Financial Access Survey (2015)</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Battle_deaths</td>\n",
       "      <td>Battle-related deaths (log of battle related d...</td>\n",
       "      <td>Early Warning Project</td>\n",
       "      <td>Peace Research Institute Oslo (PRIO) and Uppsa...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Variable Name                         Short Variable Description  \\\n",
       "0     AIDS_death                      Number of AIDS-related deaths   \n",
       "1      AIDS_Orph                                AIDS orphans (0-17)   \n",
       "2       Armedcon  Is there the presence of any type of armed con...   \n",
       "3           ATMs            Automated teller machines (per 100,000)   \n",
       "4  Battle_deaths  Battle-related deaths (log of battle related d...   \n",
       "\n",
       "          Source Extracted from  \\\n",
       "0                        UNAIDS   \n",
       "1                        UNAIDS   \n",
       "2  Silverman and Landman (2019)   \n",
       "3      UN's SDGs dataset (2018)   \n",
       "4        Early Warning Project    \n",
       "\n",
       "                               Cited Original Source Theory Selected?  \n",
       "0                                             UNAIDS                N  \n",
       "1                                             UNAIDS                Y  \n",
       "2              Uppsala Conflict Data Project (UCDP)                 Y  \n",
       "3                 IMF Financial Access Survey (2015)                Y  \n",
       "4  Peace Research Institute Oslo (PRIO) and Uppsa...                N  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_descr = pd.read_csv(\"https://raw.githubusercontent.com/ml-slavery/ml-slavery/main/Data/Meta_Data/Variable_descriptions.csv\")\n",
    "var_descr.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The variables which are marked as `Y` on the `Theory Selected?` column of the dataset, are the ones selected for the research based on the theory of [WFF GSI (2018b) Methodology, Vulnerability Model.](https://www.globalslaveryindex.org/2018/methodology/vulnerability/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of theory-selected variables:  34\n"
     ]
    }
   ],
   "source": [
    "vars_selected = var_descr[var_descr['Theory Selected?'] == 'Y']['Variable Name'].reset_index(drop=True)\n",
    "vars_selected = vars_selected.to_list()\n",
    "print(\"Number of theory-selected variables: \",len(vars_selected))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'SLAVERY', the target variable, compliments the total of $35$ variables selected by the theory.\n",
    "#### Nevertheless, there are some variables like \"AIDS_Orph\", that are splitted inside our original dataset on two years - 2016 and 2018, so we will need to do some ground work for them in order to be inherited during the training process of the new models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The problematic variables are 'AIDS_Orph', 'GDPpc', 'Gender_equal', 'Phys_secF', 'Rape_enclave', 'Rape_report'\n",
    "# We first append the original variables to the list\n",
    "vars_selected.append('AIDS_Orph_2016')\n",
    "vars_selected.append('AIDS_Orph_2018')\n",
    "vars_selected.append('GDPpc_2016')\n",
    "vars_selected.append('Gender_equal_2015')\n",
    "vars_selected.append('Phys_secF_2014')\n",
    "vars_selected.append('Phys_secF_2019')\n",
    "vars_selected.append('Rape_enclave_2015')\n",
    "vars_selected.append('Rape_report_2015')\n",
    "# Then we remove the problematic variables\n",
    "vars_selected.remove('GDPpc')\n",
    "vars_selected.remove('Gender_equal')\n",
    "vars_selected.remove('Phys_secF')\n",
    "vars_selected.remove('Rape_enclave')\n",
    "vars_selected.remove('AIDS_Orph')\n",
    "vars_selected.remove('Rape_report')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'SLAVERY'\n",
    "features_th = [col for col in vars_selected if col not in ['Country', 'Data_year', 'Region', target]]\n",
    "# Once again, we repare the train and test datasets based on the 34 selected features\n",
    "X_train_2016_th = train_data_2016[features_th]\n",
    "y_train_2016_th = train_data_2016[target]\n",
    "\n",
    "X_train_2018_th = train_data_2018[features_th]\n",
    "y_train_2018_th = train_data_2018[target]\n",
    "\n",
    "X_test_2016_th = oos_data_updated[oos_data_updated['Data_year'] == '2016'][features_th]\n",
    "y_test_2016_th = oos_data_updated[oos_data_updated['Data_year'] == '2016'][target]\n",
    "\n",
    "X_test_2018_th = oos_data_updated[oos_data_updated['Data_year'] == '2018'][features_th]\n",
    "y_test_2018_th = oos_data_updated[oos_data_updated['Data_year'] == '2018'][target]\n",
    "\n",
    "# We impute the null values from the train and test datasets once again\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "imputer.fit(X_train_2016_th)\n",
    "X_train_2016_th = imputer.transform(X_train_2016_th)\n",
    "X_test_2016_th = imputer.transform(X_test_2016_th)\n",
    "\n",
    "# Fit the imputer on the 2018 training data\n",
    "imputer.fit(X_train_2018_th)\n",
    "\n",
    "X_train_2018_th = imputer.transform(X_train_2018_th)\n",
    "X_test_2018_th = imputer.transform(X_test_2018_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Linear Regression - MAE 2016: 49714.80, MAE 2018: 14412.22\n",
      "* Ridge Regression - MAE 2016: 9529.19, MAE 2018: 4963.48\n",
      "* Lasso Regression - MAE 2016: 0.39, MAE 2018: 0.41\n",
      "* Decision Tree - MAE 2016: 0.42, MAE 2018: 0.51\n",
      "* Random Forest - MAE 2016: 0.41, MAE 2018: 0.38\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'Decision Tree': DecisionTreeRegressor(),\n",
    "    'Random Forest': RandomForestRegressor()\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Train and evaluate the model for 2016 data\n",
    "    model.fit(X_train_2016_th, y_train_2016_th)\n",
    "    y_pred_2016_th = model.predict(X_test_2016_th)\n",
    "    mae_2016 = mean_absolute_error(y_test_2016_th, y_pred_2016_th)\n",
    "    \n",
    "    # Train and evaluate the model for 2018 data\n",
    "    model.fit(X_train_2018_th, y_train_2018_th)\n",
    "    y_pred_2018_th = model.predict(X_test_2018_th)\n",
    "    mae_2018 = mean_absolute_error(y_test_2018_th, y_pred_2018_th)\n",
    "    \n",
    "    print(f\"* {name} - MAE 2016: {mae_2016:.2f}, MAE 2018: {mae_2018:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree - Top 10 Feature Importances:\n",
      "* Neonatal_mort: 0.5462\n",
      "* Internet_use: 0.1892\n",
      "* CPI: 0.0870\n",
      "* Infrastruct: 0.0439\n",
      "* Free_discuss: 0.0400\n",
      "* F_school: 0.0351\n",
      "* Literacy_15_24yrs: 0.0143\n",
      "* Armedcon: 0.0117\n",
      "* Broadband: 0.0111\n",
      "* Rape_report_2015: 0.0054\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "importances_dt = models['Decision Tree'].feature_importances_\n",
    "indices_dt = np.argsort(importances_dt)[-10:]  # Top 10 features\n",
    "import_dt_dict  = dict()\n",
    "print(\"Decision Tree - Top 10 Feature Importances:\")\n",
    "for i in indices_dt[::-1]:\n",
    "    print(f\"* {features_th[i]}: {importances_dt[i]:.4f}\")\n",
    "    import_dt_dict[features_th[i]] = importances_dt[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Top 10 Feature Importances:\n",
      "* Neonatal_mort: 0.2789\n",
      "* Internet_use: 0.2761\n",
      "* F_school: 0.0685\n",
      "* CPI: 0.0451\n",
      "* GDPpc_2016: 0.0337\n",
      "* Wasting_u5s: 0.0301\n",
      "* Free_discuss: 0.0299\n",
      "* AIDS_Orph_2016: 0.0235\n",
      "* Climate_chg_vuln: 0.0196\n",
      "* Stunting_u5s: 0.0183\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "importances_rf = models['Random Forest'].feature_importances_\n",
    "indices_rf = np.argsort(importances_rf)[-10:]\n",
    "print(\"Random Forest - Top 10 Feature Importances:\")\n",
    "import_rf_set = dict()\n",
    "for i in indices_rf[::-1]:\n",
    "    print(f\"* {features_th[i]}: {importances_rf[i]:.4f}\")\n",
    "    import_rf_set[features_th[i]] = importances_rf[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common Important Variables:\n",
      "*  Internet_use\n",
      "*  CPI\n",
      "*  Free_discuss\n",
      "*  Neonatal_mort\n",
      "*  F_school\n"
     ]
    }
   ],
   "source": [
    "common_importance_vars_reduced = set(import_dt_dict.keys()).intersection(set(import_rf_set.keys()))\n",
    "print(\"Common Important Variables:\")\n",
    "for var in common_importance_vars_reduced:\n",
    "    print(\"* \", var)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it seems, Neonatal Mortality (per 1000 live births) is once again listed as a highly important feature for predicting Slavery, as we saw in the full-dataset trained model as well. Nevertheless, besides Neonatal Mortality, the intersection of the common important features between Decision Tree and Random Forest models of the reduced model based on Theory, indicate different features than the full-datset model, as important. Those features are:\n",
    "* Female years of schooling (% male)  - `Poor education levels might result to higher slavery percentages`\n",
    "* Internet use (%) - `Lack of internet access could also result in higher levels of slavery, since lack of internet means lack of communication with the world outside country borders`\n",
    "* Freedom of discussion: Are citizens able to openly discuss political issues in private homes and in public spaces? - `Stricter regimes that limit the freedom of speech of citizens could surely lead to higher slavery percentage levels, since those are usually fascist regimes`\n",
    "* Corruption Perception Index (0-100) - `Political or other in-state corruption could possible lead to higher slavery percentage levelsdue to inequality and injustice being held among citizens and their rights`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `4. Slavery Estimation with PCA-derived Features`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# Our data are already scaled to 0-1 so we don't have to perform and additional scaling here\n",
    "pca = PCA(n_components=6)\n",
    "X_train_2016_pca = pca.fit_transform(X_train_2016)\n",
    "X_train_2018_pca = pca.fit_transform(X_train_2018)\n",
    "X_test_2016_pca = pca.transform(X_test_2016)\n",
    "X_test_2018_pca = pca.transform(X_test_2018)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Ratio from 6 PCA Components:  61.7 %\n",
      "* Component 1: 31.04%\n",
      "* Component 2: 9.24%\n",
      "* Component 3: 6.64%\n",
      "* Component 4: 5.1499999999999995%\n",
      "* Component 5: 4.91%\n",
      "* Component 6: 4.72%\n"
     ]
    }
   ],
   "source": [
    "print(\"Explained Variance Ratio from 6 PCA Components: \", round(sum(pca.explained_variance_ratio_),4)*100, \"%\")\n",
    "for i in range(6):\n",
    "    print(f\"* Component {i+1}: {round(pca.explained_variance_ratio_[i],4)*100}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top features per component - we will find what are the top 5 features per PCA component in order to get a better understanding of what each component of the PCA algorithm is comprised from. We will use the absolute values of \"loadings\" of each component, which are essentially the coefficients (weights) assigned to each original feature in the transformed principal components.\n",
    "`Loadings` indicate the contribution of each feature to the principal components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'Fuel_acc': -0.21}</td>\n",
       "      <td>{'Democ': -0.35}</td>\n",
       "      <td>{'Masskill_ever': -0.43}</td>\n",
       "      <td>{'Freemv_F': -0.35}</td>\n",
       "      <td>{'Democ': -0.37}</td>\n",
       "      <td>{'Minority_rule': -0.47}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'Freemv_F': -0.19}</td>\n",
       "      <td>{'Minority_rule': 0.27}</td>\n",
       "      <td>{'Democ': -0.39}</td>\n",
       "      <td>{'Phys_secF_2019': -0.3}</td>\n",
       "      <td>{'Rape_report_2015': -0.32}</td>\n",
       "      <td>{'Soc_powerdist': 0.44}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'Armedcon': 0.19}</td>\n",
       "      <td>{'Armedcon': 0.27}</td>\n",
       "      <td>{'Rape_enclave_2015': -0.31}</td>\n",
       "      <td>{'Inequality': -0.28}</td>\n",
       "      <td>{'Freemv_F': 0.3}</td>\n",
       "      <td>{'Freemv_F': -0.28}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'Piped_water': -0.18}</td>\n",
       "      <td>{'Fuel_acc': 0.2}</td>\n",
       "      <td>{'Armedcon': -0.3}</td>\n",
       "      <td>{'Minority_rule': -0.27}</td>\n",
       "      <td>{'M_school': 0.26}</td>\n",
       "      <td>{'Gender_equal_2015': 0.26}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'Internet_use': -0.18}</td>\n",
       "      <td>{'VDEM_Libdem': -0.19}</td>\n",
       "      <td>{'Masskill_ongo': -0.26}</td>\n",
       "      <td>{'GDPpc_growth': 0.26}</td>\n",
       "      <td>{'Armedcon': 0.24}</td>\n",
       "      <td>{'Masskill_ever': -0.22}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'Stunting_u5s': 0.17}</td>\n",
       "      <td>{'Rape_enclave_2015': 0.17}</td>\n",
       "      <td>{'Minority_rule': 0.2}</td>\n",
       "      <td>{'Masskill_ongo': 0.21}</td>\n",
       "      <td>{'Phys_secF_2019': -0.19}</td>\n",
       "      <td>{'Pol_cand_restr': -0.17}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       PC1                          PC2  \\\n",
       "0      {'Fuel_acc': -0.21}             {'Democ': -0.35}   \n",
       "1      {'Freemv_F': -0.19}      {'Minority_rule': 0.27}   \n",
       "2       {'Armedcon': 0.19}           {'Armedcon': 0.27}   \n",
       "3   {'Piped_water': -0.18}            {'Fuel_acc': 0.2}   \n",
       "4  {'Internet_use': -0.18}       {'VDEM_Libdem': -0.19}   \n",
       "5   {'Stunting_u5s': 0.17}  {'Rape_enclave_2015': 0.17}   \n",
       "\n",
       "                            PC3                       PC4  \\\n",
       "0      {'Masskill_ever': -0.43}       {'Freemv_F': -0.35}   \n",
       "1              {'Democ': -0.39}  {'Phys_secF_2019': -0.3}   \n",
       "2  {'Rape_enclave_2015': -0.31}     {'Inequality': -0.28}   \n",
       "3            {'Armedcon': -0.3}  {'Minority_rule': -0.27}   \n",
       "4      {'Masskill_ongo': -0.26}    {'GDPpc_growth': 0.26}   \n",
       "5        {'Minority_rule': 0.2}   {'Masskill_ongo': 0.21}   \n",
       "\n",
       "                           PC5                          PC6  \n",
       "0             {'Democ': -0.37}     {'Minority_rule': -0.47}  \n",
       "1  {'Rape_report_2015': -0.32}      {'Soc_powerdist': 0.44}  \n",
       "2            {'Freemv_F': 0.3}          {'Freemv_F': -0.28}  \n",
       "3           {'M_school': 0.26}  {'Gender_equal_2015': 0.26}  \n",
       "4           {'Armedcon': 0.24}     {'Masskill_ever': -0.22}  \n",
       "5    {'Phys_secF_2019': -0.19}    {'Pol_cand_restr': -0.17}  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadings_df = pd.DataFrame(pca.components_, columns=features, index=[f'PC{i+1}' for i in range(6)]).T\n",
    "\n",
    "top_features_per_component = {}\n",
    "for component in loadings_df.columns:\n",
    "    top_features_values = loadings_df[component].loc[loadings_df[component].apply(np.abs).nlargest(6).index]\n",
    "    top_features = top_features_values.index.tolist()\n",
    "    top_values = top_features_values.values.tolist()\n",
    "    top_features_per_component[component] = [{feature: round(value, 2)} for feature, value in zip(top_features, top_values)]\n",
    "\n",
    "top_features_df = pd.DataFrame(top_features_per_component)\n",
    "top_features_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on the above table indicating the wights of the top features per component, we could claim the following assumptions:\n",
    "* `PC1`: Represents a mix of socio-economic development and conflict factors. It includes access to non-solid fuels, freedom of movement for women, armed conflict, piped water, Internet use, and the prevalence of stunting in under-5s. It may represent the `general living conditions and access to basic resources` in a country.\n",
    "\n",
    "* `PC2`: Represents a combination of political and conflict-related factors, as well as access to resources. It includes democracy, minority rule, armed conflict, access to non-solid fuels, the level of liberal democracy, and the prevalence of rape in enclaves. It may represent the `political environment and the stability of a country`.\n",
    "\n",
    "* `PC3`: Reflects factors related to conflict, political structure, and violence. It includes the occurrence of mass killings, democracy, prevalence of rape in enclaves, armed conflict, ongoing mass killings, and minority rule. It may represent the `level of violence and political instability` in a country.\n",
    "\n",
    "* `PC4`: Captures factors related to personal freedom, security, inequality, and economic growth. It includes freedom of movement for women, physical security for women in 2019, inequality, minority rule, GDP per capita growth, and ongoing mass killings. It may represent the `overall well-being and security` in a country.\n",
    "\n",
    "* `PC5`: Represents a mix of political, conflict-related, and women-related factors. It includes democracy, the prevalence of rape reported in 2015, freedom of movement for women, female labor force participation relative to males, armed conflict, and physical security for women in 2019. It may represent the `level of gender equality and political stability, as well as quality of life for women` in a country.\n",
    "\n",
    "* `PC6`: Reflects factors related to political power distribution, personal freedom, gender equality, and violence. It includes minority rule, the distribution of power by social group, freedom of movement for women, gender equality in 2015, occurrence of mass killings, and restrictions on political candidates. It may represent the `overall balance of power and inclusiveness in a country's political system`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll train and evaluate the models on the PCA-derived features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Linear Regression - MAE 2016 (PCA): 153.80, MAE 2018 (PCA): 2213.79\n",
      "* Ridge Regression - MAE 2016 (PCA): 149.42, MAE 2018 (PCA): 2066.30\n",
      "* Lasso Regression - MAE 2016 (PCA): 0.39, MAE 2018 (PCA): 0.41\n",
      "* Decision Tree - MAE 2016 (PCA): 0.45, MAE 2018 (PCA): 0.40\n",
      "* Random Forest - MAE 2016 (PCA): 0.35, MAE 2018 (PCA): 0.36\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    # Train and evaluate the model for 2016 data\n",
    "    model.fit(X_train_2016_pca, y_train_2016)\n",
    "    y_pred_2016_pca = model.predict(X_test_2016_pca)\n",
    "    mae_2016_pca = mean_absolute_error(y_test_2016, y_pred_2016_pca)\n",
    "    \n",
    "    # Train and evaluate the model for 2018 data\n",
    "    model.fit(X_train_2018_pca, y_train_2018)\n",
    "    y_pred_2018_pca = model.predict(X_test_2018_pca)\n",
    "    mae_2018_pca = mean_absolute_error(y_test_2018, y_pred_2018_pca)\n",
    "    \n",
    "    print(f\"* {name} - MAE 2016 (PCA): {mae_2016_pca:.2f}, MAE 2018 (PCA): {mae_2018_pca:.2f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe an improved MAE in most models\n",
    "### Variable Importance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Decision Tree Variable Importance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree - Top 10 Feature Importances:\n",
      "* Component_1: 0.4916\n",
      "* Component_2: 0.2244\n",
      "* Component_3: 0.1336\n",
      "* Component_4: 0.0211\n",
      "* Component_5: 0.1241\n",
      "* Component_6: 0.0051\n"
     ]
    }
   ],
   "source": [
    "importances_dt = models['Decision Tree'].feature_importances_\n",
    "import_dt_dict  = dict()\n",
    "print(\"Decision Tree - Top 10 Feature Importances:\")\n",
    "for idx, i in enumerate(importances_dt):\n",
    "    print(f\"* Component_{idx+1}: {i:.4f}\")\n",
    "    import_dt_dict[f\"Component_{idx+1}\"] = i"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Random Forest Variable Importance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Top 10 Feature Importances:\n",
      "* Component_1: 0.5217\n",
      "* Component_2: 0.1003\n",
      "* Component_3: 0.1769\n",
      "* Component_4: 0.0290\n",
      "* Component_5: 0.1202\n",
      "* Component_6: 0.0519\n"
     ]
    }
   ],
   "source": [
    "importances_rf = models['Random Forest'].feature_importances_\n",
    "import_rf_dict  = dict()\n",
    "print(\"Random Forest - Top 10 Feature Importances:\")\n",
    "for idx, i in enumerate(importances_rf):\n",
    "    print(f\"* Component_{idx+1}: {i:.4f}\")\n",
    "    import_rf_dict[f\"Component_{idx+1}\"] = i"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the first 3 components (explaining the most variability of the dataset) pay the greater role on predicting \"SLAVERY\". We can observe that the $5th$ component is taken into account as well, indicating that living conditions for women in a country as well as the political stability of it, might be significant factors to uprising of slavery in the country.\n",
    "The first three components, as we discussed before, propose a mixture of general living conditions, access to resources, political instability and levels of violence in a country. Our models tend to take into account factors related to those matters in order to predict slavery, so in conclusion, the raise or reduction of variables related to such instances, configure the levels of slavery in the region, with perhaps the most significant one those having to do with access to resources,and general living conditions such as access to non-solid fuels, freedom of movement for women, armed conflict, piped water and Internet use.\n",
    "* We can understand that on countries suffering from war conditions, slavery is a common phenomenon, as well as in regimes that deny peoples's and more particularly women's rights. \n",
    "* Furthermore, lack of internet use means lack of information, innovation and eventually education - factors that are crucial for the reformation of conditions of living and mentality of people.\n",
    "* Eventually, the disability of accessing basic resources like clean piped water or fuels are amongst the main ingredients that lead to poverty and poor living conditions, eventually contributing to the raise of levels of exploitation of people.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practicum_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
